export default {
  'AI': 'IA',
  'Activation': 'Activación',
  'Activation function': 'Función de activación',
  'Bias': 'Sesgo',
  'Clamped': 'Clamped',
  'Clamped function: f(x) = 0 for x < 0, f(x) = 1 for x > 1, else f(x) = x': 'Función Clamped: f(x) = 0 para x < 0, f(x) = 1 para x > 1, else f(x) = x',
  'Clamped Symmetric': 'Clamped simétrico',
  'Clamped Symmetric function: f(x) = -1 for x < -1, f(x) = 1 for x > 1, else f(x) = x': 'Función Clamped simétrico: f(x) = -1 para x < -1, f(x) = 1 para x > 1, else f(x) = x',
  'ELU': 'ELU',
  'Exponential Linear Unit: f(x) = x for x >= 0, else e^x - 1': 'Unidad lineal exponencial: f(x) = x para x >= 0, else e^x - 1',
  'GELU': 'GELU',
  'Gaussian Error Linear Unit: f(x) = 0.5 * x * (1 + tanh(√(2/π) * (x + 0.044715 * x³)))': 'Unidad lineal de error gaussiano: f(x) = 0.5 * x * (1 + tanh(√(2/π) * (x + 0.044715 * x³)))',
  'Hyperbolic Tangent: f(x) = (e^x - e^(-x)) / (e^x + e^(-x))': 'Tangente hiperbólica: f(x) = (e^x - e^(-x)) / (e^x + e^(-x))',
  'Identity': 'Identidad',
  'Identity function: f(x) = x': 'Función identidad: f(x) = x',
  'Inputs count': 'Cantidad de entradas',
  'Leaky ReLU': 'Leaky ReLU (ReLU con fugas)',
  'Leaky Rectified Linear Unit: f(x) = x for x > 0, else 0.01 * x': 'Unidad lineal rectificada con fugas: f(x) = x para x > 0, else 0.01 * x',
  'Mean Squared Error: E = (1/n) Σ (y_i - r_i)^2': 'Error cuadrático medio: E = (1/n) Σ (y_i - r_i)^2',
  'MSE': 'ECM',
  'Neural Network': 'Red neuronal',
  'Neural Network Viewer': 'Visor de redes neuronales',
  'Perceptron': 'Perceptrón',
  'Rectified Linear Unit: f(x) = x for x > 0, else 0': 'Unidad lineal rectificada: f(x) = x para x > 0, else 0',
  'ReLU': 'ReLU',
  'Scaled Exponential Linear Unit: f(x) = 1.0507 * x for x >= 0, else 1.0507 * (e^x - 1)': 'Unidad lineal exponencial escalada: f(x) = 1.0507 * x para x >= 0, else 1.0507 * (e^x - 1)',
  'SELU': 'SELU',
  'Sigmoid': 'Sigmoide',
  'Sigmoid function: f(x) = 1 / (1 + e^(-x))': 'Función sigmoide: f(x) = 1 / (1 + e^(-x))',
  'Softmax': 'Softmax',
  'Softmax function: f(x) = e^(x_i) / Σ e^(x_j) for all j': 'Función Softmax: f(x) = e^(x_i) / Σ e^(x_j) para todo j',
  'Step': 'Escalón',
  'Step function: f(x) = 1 for x >= 0, else 0': 'Función escalón: f(x) = 1 para x >= 0, else 0',
  'Swish / SiLU': 'Swish / SiLU',
  'Swish / Sigmoid Linear Unit: f(x) = x / (1 + e^(-x))': 'Swish / Unidad lineal sigmoide: f(x) = x / (1 + e^(-x))',
  'Tanh': 'Tanh',
  'Weights': 'Pesos',
  'XOR with Perceptron': 'XOR con Perceptrón',
};
